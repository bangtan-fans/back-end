{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store openAI and pinecone api keys here \n",
    "OPEN_AI_KEY = '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'\n",
    "PINECONE_KEY = '1a7ce1a3-61ce-4d9b-8271-f6984da1ad9d'\n",
    "PINECONE_ENV = 'us-west4-gcp-free'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/67/78/7588a047e458cb8075a4089d721d7af5e143ff85a2388d4a28c530be0494/openai-0.27.8-py3-none-any.whl.metadata\n",
      "  Downloading openai-0.27.8-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\allis\\miniconda3\\envs\\grailnotes\\lib\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\allis\\miniconda3\\envs\\grailnotes\\lib\\site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\allis\\miniconda3\\envs\\grailnotes\\lib\\site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\allis\\miniconda3\\envs\\grailnotes\\lib\\site-packages (from requests>=2.20->openai) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\allis\\miniconda3\\envs\\grailnotes\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\allis\\miniconda3\\envs\\grailnotes\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\allis\\miniconda3\\envs\\grailnotes\\lib\\site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\allis\\miniconda3\\envs\\grailnotes\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\allis\\miniconda3\\envs\\grailnotes\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\allis\\miniconda3\\envs\\grailnotes\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\allis\\miniconda3\\envs\\grailnotes\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\allis\\miniconda3\\envs\\grailnotes\\lib\\site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\allis\\miniconda3\\envs\\grailnotes\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\allis\\miniconda3\\envs\\grailnotes\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
      "   ---------------------------------------- 0.0/73.6 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 10.2/73.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 73.6/73.6 kB 1.0 MB/s eta 0:00:00\n",
      "Installing collected packages: openai\n",
      "Successfully installed openai-0.27.8\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's an example Python script that trains a neural network on simulated data using the Keras library:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense\n",
      "\n",
      "# Generate simulated data\n",
      "np.random.seed(0)\n",
      "X = np.random.rand(1000, 10)\n",
      "y = np.random.randint(2, size=(1000, 1))\n",
      "\n",
      "# Define the model architecture\n",
      "model = Sequential()\n",
      "model.add(Dense(32, input_dim=10, activation='relu'))\n",
      "model.add(Dense(1, activation='sigmoid'))\n",
      "\n",
      "# Compile the model\n",
      "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
      "\n",
      "# Train the model\n",
      "model.fit(X, y, epochs=10, batch_size=32)\n",
      "\n",
      "# Evaluate the model\n",
      "loss, accuracy = model.evaluate(X, y)\n",
      "print(f'Loss: {loss}, Accuracy: {accuracy}')\n",
      "```\n",
      "\n",
      "In this script, we first generate simulated data using `numpy.random.rand` and `numpy.random.randint` functions. The input data `X` is a 2D array of shape `(1000, 10)` and the target labels `y` is a 2D array of shape `(1000, 1)`.\n",
      "\n",
      "Then, we define the model architecture using the `Sequential` class from Keras. In this example, the model has one hidden layer with 32 units and a ReLU activation function, and an output layer with one unit and a sigmoid activation function.\n",
      "\n",
      "Next, we compile the model using the `compile` method, specifying the loss function, optimizer, and evaluation metric.\n",
      "\n",
      "We then train the model using the `fit` method, specifying the input data `X` and target labels `y`, the number of epochs, and the batch size.\n",
      "\n",
      "Finally, we evaluate the trained model using the `evaluate` method and print the loss and accuracy.\n"
     ]
    }
   ],
   "source": [
    "# import schema for chat messages and ChatOpenAI in order to query chatmodels GPT-3.5-turbo or GPT-4\n",
    "import langchain \n",
    "\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "     \n",
    "\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0.3, openai_api_key = OPEN_AI_KEY)\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are an expert data scientist\"),\n",
    "    HumanMessage(content=\"Write a Python script that trains a neural network on simulated data \")\n",
    "]\n",
    "response=chat(messages)\n",
    "\n",
    "print(response.content,end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A Autoencoder is a type of neural network model which is used for learning representation of input data. It works by learning how to represent input data as a compressed version, while also learning to reverse the process (decoding) to reconstruct\n",
      "\n",
      "Regularization is a technique used in machine learning to mitigate overfitting by introducing a penalty term to the cost function of a model. This penalty term penalizes for large values of parameters, and thus reduces their effect on the model's performance, allowing\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "# Define the prompt template\n",
    "template = \"\"\"\n",
    "You are an expert data scientist with an expertise in building deep learning models. \n",
    "Explain the concept of {concept} in a couple of lines\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"concept\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "# Define a function to call the OpenAI model\n",
    "def llm(formatted_prompt):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=formatted_prompt,\n",
    "        max_tokens=50\n",
    "    )\n",
    "    return response.choices[0].text\n",
    "\n",
    "# Run LLM with PromptTemplate\n",
    "print(llm(prompt.format(concept=\"autoencoder\")))\n",
    "print(llm(prompt.format(concept=\"regularization\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allis\\miniconda3\\envs\\grailNotes\\Lib\\site-packages\\langchain\\llms\\openai.py:170: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "c:\\Users\\allis\\miniconda3\\envs\\grailNotes\\Lib\\site-packages\\langchain\\llms\\openai.py:624: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basketball is a dynamic team sport that involves two teams of five players each, aiming to score points by shooting a ball through the opponents' hoop while defending their own. It requires a combination of physical skills such as agility, coordination, and strength, as well as strategic understanding, teamwork, and quick decision-making.\n"
     ]
    }
   ],
   "source": [
    "# Import LLMChain and define chain with language model and prompt as arguments.\n",
    "from langchain.chains import LLMChain, llm\n",
    "from langchain.llms.openai import OpenAI\n",
    "\n",
    "model = OpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key = OPEN_AI_KEY)\n",
    "\n",
    "\n",
    "# Define the prompt template\n",
    "template = \"\"\"\n",
    "You are a sports scientist with an expertise in {concept}.\n",
    "Explain the concept of {concept} in a couple of lines\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"concept\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "\n",
    "chain = LLMChain(llm=model, prompt=prompt)\n",
    "\n",
    "# Run the chain only specifying the input variable.\n",
    "print(chain.run(\"basketball\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mAn autoencoder is a type of neural network model that is trained to reconstruct its input data. It consists of an encoder network that compresses the input data into a lower-dimensional representation, and a decoder network that reconstructs the original input data from this representation. Autoencoders are commonly used for tasks such as dimensionality reduction, feature extraction, and anomaly detection.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mAn autoencoder is like a special machine that learns to copy things. Let's say you have a picture and you want the machine to learn how to make an exact copy of it. \n",
      "\n",
      "To do this, the machine has two important parts. The first part is called the encoder, and it takes the picture and tries to understand what makes it unique. It learns to pick out the important details and puts all this information together in a smaller package. It's like when you play with 100 puzzle pieces, but you only need to remember 20 key pieces to put the puzzle together. This smaller package is called a compressed representation.\n",
      "\n",
      "Now, the second part is called the decoder. It takes the compressed representation made by the encoder and tries to reconstruct the original picture. It's like having those 20 key puzzle pieces and using them to recreate the whole puzzle. The decoder's job is to take this compressed information and fill in the missing details, adding the colors and shapes back until it looks exactly like the original picture again.\n",
      "\n",
      "So, why do we need a machine to do this? Well, autoencoders have many cool uses! One way they can be used is for dimensionality reduction. Imagine you have a big box of toys with many different shapes, sizes, and colors. It's difficult to sort through all of them and organize them. But if you had an autoencoder, it could learn to simplify the toys by picking out the most important features, like the shape or color, and create a smaller representation of each toy. This makes it easier to organize and find toys that are similar.\n",
      "\n",
      "Another great use for autoencoders is feature extraction. Imagine you have a picture of a cat and a dog, and you want the machine to understand what makes each animal different. The encoder part of the autoencoder can learn the important features of each animal, like the shape of the ears or the color of the fur. Then, you can use this learned information to tell the machine to identify other cats or dogs in different pictures. \n",
      "\n",
      "Autoencoders are also helpful for detecting things that are strange or unusual, like finding a needle in a haystack. Let's say you show the machine pictures of apples, oranges, and then suddenly a picture of a banana. The autoencoder has learned what apples and oranges look like, so when it sees a banana, it realizes it's different. It can then alert you that something strange or unusual has been found.\n",
      "\n",
      "So, an autoencoder is a special machine that learns to make copies of things by understanding their important details, compressing this information into a smaller package, and using it to recreate the original thing. It can be used to organize and find similar items, identify important features of objects, and detect anything unusual.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "An autoencoder is like a special machine that learns to copy things. Let's say you have a picture and you want the machine to learn how to make an exact copy of it. \n",
      "\n",
      "To do this, the machine has two important parts. The first part is called the encoder, and it takes the picture and tries to understand what makes it unique. It learns to pick out the important details and puts all this information together in a smaller package. It's like when you play with 100 puzzle pieces, but you only need to remember 20 key pieces to put the puzzle together. This smaller package is called a compressed representation.\n",
      "\n",
      "Now, the second part is called the decoder. It takes the compressed representation made by the encoder and tries to reconstruct the original picture. It's like having those 20 key puzzle pieces and using them to recreate the whole puzzle. The decoder's job is to take this compressed information and fill in the missing details, adding the colors and shapes back until it looks exactly like the original picture again.\n",
      "\n",
      "So, why do we need a machine to do this? Well, autoencoders have many cool uses! One way they can be used is for dimensionality reduction. Imagine you have a big box of toys with many different shapes, sizes, and colors. It's difficult to sort through all of them and organize them. But if you had an autoencoder, it could learn to simplify the toys by picking out the most important features, like the shape or color, and create a smaller representation of each toy. This makes it easier to organize and find toys that are similar.\n",
      "\n",
      "Another great use for autoencoders is feature extraction. Imagine you have a picture of a cat and a dog, and you want the machine to understand what makes each animal different. The encoder part of the autoencoder can learn the important features of each animal, like the shape of the ears or the color of the fur. Then, you can use this learned information to tell the machine to identify other cats or dogs in different pictures. \n",
      "\n",
      "Autoencoders are also helpful for detecting things that are strange or unusual, like finding a needle in a haystack. Let's say you show the machine pictures of apples, oranges, and then suddenly a picture of a banana. The autoencoder has learned what apples and oranges look like, so when it sees a banana, it realizes it's different. It can then alert you that something strange or unusual has been found.\n",
      "\n",
      "So, an autoencoder is a special machine that learns to make copies of things by understanding their important details, compressing this information into a smaller package, and using it to recreate the original thing. It can be used to organize and find similar items, identify important features of objects, and detect anything unusual.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "You are an expert data scientist with an expertise in building deep learning models. \n",
    "Explain the concept of {concept} in a couple of lines\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"concept\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=model, prompt=prompt)\n",
    "\n",
    "\n",
    "# Define a second prompt \n",
    "\n",
    "second_prompt = PromptTemplate(\n",
    "    input_variables=[\"ml_concept\"],\n",
    "    template=\"Turn the concept description of {ml_concept} and explain it to me like I'm five in 500 words\",\n",
    ")\n",
    "chain_two = LLMChain(llm=model, prompt=second_prompt)\n",
    "\n",
    "# Define a sequential chain using the two chains above: the second chain takes the output of the first chain as input\n",
    "\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)\n",
    "\n",
    "# Run the chain specifying only the input variable for the first chain.\n",
    "explanation = overall_chain.run(\"autoencoder\")\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allis\\miniconda3\\envs\\grailNotes\\Lib\\site-packages\\langchain\\llms\\openai.py:170: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "c:\\Users\\allis\\miniconda3\\envs\\grailNotes\\Lib\\site-packages\\langchain\\llms\\openai.py:624: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mBasketball is a fast-paced team sport played on a rectangular court, with the objective of scoring points by shooting the ball into the opponent's hoop while preventing them from scoring on your own. It requires agility, coordination, and strategy, with players dribbling, passing, and shooting the ball to ultimately outscore their opponents within a designated time period.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mOnce upon a time, in the small town of Fairwood, there lived a young boy named Allister Lim. Allister was an avid basketball player and had dreamt of playing the sport professionally since he was a little boy. He admired the agility, coordination, and strategy involved in the game, and he worked tirelessly to improve his skills.\n",
      "\n",
      "Allister's love for basketball grew even more when he joined the Fairwood Middle School basketball team. The team had an important tournament coming up, and Allister knew that this was his chance to prove himself on the court. He practiced dribbling, passing, and shooting day and night, determined to excel in the game he loved so dearly.\n",
      "\n",
      "The tournament day arrived, and Allister stood proudly on the rectangular court, with his teammates by his side. The energy in the air was palpable, and Allister could feel his heart pounding with excitement. As the referee blew the whistle, the game began.\n",
      "\n",
      "Allister's team played flawlessly, showcasing their agility and coordination as they swiftly moved across the court. Allister, with his quick footwork, dribbled the ball past opponents, leaving them stunned. His passes were spot-on, leading to various scoring opportunities for his teammates.\n",
      "\n",
      "The game was fast-paced and intense, with both teams engaging in a battle of endurance and skill. Allister's opponents were tough, matching his every move and blocking his every shot. But Allister was determined, never giving up. He adjusted his strategy, studying his opponents' play patterns, and used his agility to maneuver past them, time and time again.\n",
      "\n",
      "Throughout the game, Allister's shots echoed triumphantly as the ball swished through the opposing team's hoop. The crowd roared with appreciation, encouragement, and awe at the talented young player before them. Allister was in his element, leaving everything on the court as he chased his dreams.\n",
      "\n",
      "As the time ticked away, Allister's team managed to outscore their opponents, securing a well-earned victory. Allister's face beamed with pride as he hugged his teammates, celebrating a job well done. The tournament had taught him the importance of teamwork, resilience, and determination. It had shown him that dreams were achievable if one had the right spirit and put in the hard work.\n",
      "\n",
      "Word of Allister's exceptional performance spread like wildfire throughout Fairwood. The townspeople's support and admiration boosted Allister's confidence, and he continued to train relentlessly, nurturing his skills and embracing his love for the game.\n",
      "\n",
      "Years later, Allister Lim became a renowned basketball player, his name etched in the annals of basketball history. He always looked back fondly on his humble beginnings in Fairwood, crediting his success to the lessons he learned on that very court. Allister's journey had shown him that basketball was not just a game; it was a way of life that demanded dedication, sacrifice, and a burning passion for the sport.\n",
      "\n",
      "And so, Allister Lim went on to inspire generations to come, leaving an everlasting legacy that would forever be synonymous with the exhilarating, fast-paced team sport that is basketball.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Once upon a time, in the small town of Fairwood, there lived a young boy named Allister Lim. Allister was an avid basketball player and had dreamt of playing the sport professionally since he was a little boy. He admired the agility, coordination, and strategy involved in the game, and he worked tirelessly to improve his skills.\n",
      "\n",
      "Allister's love for basketball grew even more when he joined the Fairwood Middle School basketball team. The team had an important tournament coming up, and Allister knew that this was his chance to prove himself on the court. He practiced dribbling, passing, and shooting day and night, determined to excel in the game he loved so dearly.\n",
      "\n",
      "The tournament day arrived, and Allister stood proudly on the rectangular court, with his teammates by his side. The energy in the air was palpable, and Allister could feel his heart pounding with excitement. As the referee blew the whistle, the game began.\n",
      "\n",
      "Allister's team played flawlessly, showcasing their agility and coordination as they swiftly moved across the court. Allister, with his quick footwork, dribbled the ball past opponents, leaving them stunned. His passes were spot-on, leading to various scoring opportunities for his teammates.\n",
      "\n",
      "The game was fast-paced and intense, with both teams engaging in a battle of endurance and skill. Allister's opponents were tough, matching his every move and blocking his every shot. But Allister was determined, never giving up. He adjusted his strategy, studying his opponents' play patterns, and used his agility to maneuver past them, time and time again.\n",
      "\n",
      "Throughout the game, Allister's shots echoed triumphantly as the ball swished through the opposing team's hoop. The crowd roared with appreciation, encouragement, and awe at the talented young player before them. Allister was in his element, leaving everything on the court as he chased his dreams.\n",
      "\n",
      "As the time ticked away, Allister's team managed to outscore their opponents, securing a well-earned victory. Allister's face beamed with pride as he hugged his teammates, celebrating a job well done. The tournament had taught him the importance of teamwork, resilience, and determination. It had shown him that dreams were achievable if one had the right spirit and put in the hard work.\n",
      "\n",
      "Word of Allister's exceptional performance spread like wildfire throughout Fairwood. The townspeople's support and admiration boosted Allister's confidence, and he continued to train relentlessly, nurturing his skills and embracing his love for the game.\n",
      "\n",
      "Years later, Allister Lim became a renowned basketball player, his name etched in the annals of basketball history. He always looked back fondly on his humble beginnings in Fairwood, crediting his success to the lessons he learned on that very court. Allister's journey had shown him that basketball was not just a game; it was a way of life that demanded dedication, sacrifice, and a burning passion for the sport.\n",
      "\n",
      "And so, Allister Lim went on to inspire generations to come, leaving an everlasting legacy that would forever be synonymous with the exhilarating, fast-paced team sport that is basketball.\n"
     ]
    }
   ],
   "source": [
    "# Import LLMChain and define chain with language model and prompt as arguments.\n",
    "from langchain.chains import LLMChain, llm\n",
    "from langchain.llms.openai import OpenAI\n",
    "\n",
    "model = OpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key = OPEN_AI_KEY)\n",
    "\n",
    "\n",
    "# Define the prompt template\n",
    "template = \"\"\"\n",
    "You are a sports scientist with an expertise in {concept}.\n",
    "Explain the concept of {concept} in a couple of lines\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"concept\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "\n",
    "chain = LLMChain(llm=model, prompt=prompt)\n",
    "\n",
    "# Define a second prompt \n",
    "\n",
    "second_prompt = PromptTemplate(\n",
    "    input_variables=[\"concept2\"],\n",
    "    template=\"Turn the concept description of {concept2} and write a short story about it involving a character named Allister Lim\",\n",
    ")\n",
    "chain_two = LLMChain(llm=model, prompt=second_prompt)\n",
    "\n",
    "# Define a sequential chain using the two chains above: the second chain takes the output of the first chain as input\n",
    "\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)\n",
    "\n",
    "# Run the chain specifying only the input variable for the first chain.\n",
    "explanation = overall_chain.run(\"basketball\")\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "# Import utility for splitting up texts and split up the explanation given above into document chunks\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap  = 0,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([explanation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once upon a time, in the small town of Fairwood, there lived a young boy named Allister Lim.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.4.0-cp311-cp311-win_amd64.whl (635 kB)\n",
      "     ---------------------------------------- 0.0/635.3 kB ? eta -:--:--\n",
      "      --------------------------------------- 10.2/635.3 kB ? eta -:--:--\n",
      "     - ----------------------------------- 30.7/635.3 kB 330.3 kB/s eta 0:00:02\n",
      "     ----- ------------------------------- 92.2/635.3 kB 655.4 kB/s eta 0:00:01\n",
      "     ----------------------------- -------- 491.5/635.3 kB 2.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- 635.3/635.3 kB 3.1 MB/s eta 0:00:00\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Obtaining dependency information for regex>=2022.1.18 from https://files.pythonhosted.org/packages/de/cd/d80c9e284ae6c1b2172dacf0651d25b78ee1f7efbc12d74ea7b87c766263/regex-2023.8.8-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading regex-2023.8.8-cp311-cp311-win_amd64.whl.metadata (42 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\allis\\miniconda3\\envs\\grailnotes\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\allis\\miniconda3\\envs\\grailnotes\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\allis\\miniconda3\\envs\\grailnotes\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\allis\\miniconda3\\envs\\grailnotes\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\allis\\miniconda3\\envs\\grailnotes\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
      "Downloading regex-2023.8.8-cp311-cp311-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.3 kB ? eta -:--:--\n",
      "   ---------------------------------------  266.2/268.3 kB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 268.3/268.3 kB 5.6 MB/s eta 0:00:00\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2023.8.8 tiktoken-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.018737535412937274, -0.023208110891932626, 0.0037870296641751614, -0.027393604813319154, -0.018063710510055286, 0.02237878678829627, -0.01908740721765077, -0.017610173192387245, 0.009187353524459459, -0.017752713971191655, 0.004622832745955855, 0.012290838770798255, 0.010735857007802642, -0.012446337040230071, 0.011202350884775543, 0.002858899688646135, 0.021873417645473507, -0.007347291135177576, 0.009582577943352702, 0.0018918950293438362, -0.0007143199714755977, 0.008656067537736784, 0.00021745454567493862, 0.0037481550968172074, 0.009614973998227591, -0.013359889023896034, 0.013567220049805123, -0.014577958335450654, 0.009414121251970931, -0.013787509497664167, 0.022637949639360083, -0.008882836196570805, 0.004839882122666134, -0.008370987842773061, -0.040196291006592604, -0.018556121230928094, -0.0007471203949598288, -0.022573159392255404, 0.008137739972964063, -0.009219748648011799, 0.019942648165187035, -0.008474653355727606, -0.005410042443916127, -0.01698818197730508, -0.009303977459363958, 0.005701601349854826, -0.006547123015267348, 0.003294618710471714, -0.018789369100737096, 0.018439497296023597, 0.008364508631798084, 0.020266601263355524, 0.0035116683200126318, -0.01363201122823235, -0.027860098690292052, 0.0037481550968172074, 0.015536863864618911, 0.0012164496252261925, -0.012193652468818688, -0.016197731276873493, -0.0028119263404000963, 0.013269181932891446, -0.0046163535349808766, -0.014707540692305107, -0.013502428871377896, 0.005565540713347943, -0.015692362134050727, -0.002820025121288181, -0.0010650008626537375, 0.011416161121659607, 0.022119622074587363, -0.003945767306263829, 0.0006811145973054304, -0.01920403115255527, 0.003987881711939909, -0.0034663145416797, -0.007055731763577602, 0.01611998260781886, -0.020149979191096123, 0.008805086596193622, -0.0016311115606290503, -0.004703821486159251, -0.027600935839228243, 0.030762733053019287, 0.04050728940810133, 0.011519826634614152, -0.0006547933265885176, 0.025229587463223683, -0.019540942672673714, 0.012530564920259682, -0.006174575369125252, 0.02559241582724204, 0.01698818197730508, 0.013398763358423351, 0.019346570068714583, -0.002228807830030786, -0.02697894276150098, 0.02228807969729168, 0.00800167933645718, -0.01744171743232802, -0.00041911630563666585, 0.0003676884998453299, -0.0274972703262737, -0.007386165469704893, -0.029207750358701125, -0.0204480173080098, 0.0074315194808684615, -0.01513516023475069, 0.021238466145796286, 0.007230667665934352, -0.009524265975900453, 0.0014893813816884245, 0.048308114135656756, -0.042010436551974575, -0.012342671527275527, -0.016366188899577812, 0.012148298923316394, 0.0048560801501035785, -0.003456595958047871, 0.001169476276980154, 0.010295278112084555, 0.02827476074211023, -0.0012480351966526154, -0.013398763358423351, -0.0106321914948481, 0.032732377799155624, -0.03586825630640166, -0.007813785943473024, 0.0038097064369263084, 0.001439978329326769, 0.008915231320123144, -0.0055396243351093066, 0.0207978872500782, -0.01109220709216857, -0.011500389933011768, -0.0011322213959506255, 0.0013120162408773333, 0.012951706183052835, -0.010535005192868532, -0.02876717146298304, 0.00970568108923218, 0.0042632430561024386, -0.002674245435488194, 0.00048471712350129845, 0.007872097910925274, 0.02723810561256479, 0.01689747302365539, 0.00026301066838360486, 0.003968444079014976, -0.01551094795204155, 0.012174214835893754, -0.014837122117837014, 0.02879308830688295, -0.012349150738250504, 0.029155916670901307, 0.010230486933657329, 0.010327674166959445, 0.005643289848063851, -0.03223996521563772, 0.0047556542426365235, 0.003838862420652433, 0.012757333579093703, 0.012653668066139158, -0.02105705196378711, 0.012148298923316394, 0.024763091723605687, 0.009433558884895863, 0.0013670886028420942, 0.004392824947295619, -0.012465774673155003, 0.004188733526874019, 0.012413941916677732, -0.05556470004247484, 0.02016293575040098, 0.0006462894785991782, 0.0032687023322330784, -0.005633571031601384, 0.018724576990987316, -0.017636090036287154, -0.0004713539836960443, -0.027445436638473878, -0.0025543823607574808, 0.00800167933645718, 0.012413941916677732, -0.012919311059500498, 0.002577059133508628, -0.017273261672268798, -0.015238825747705234, -0.007295458378700304, 0.0013395524218597138, 0.0040785888029444975, 0.013800467919614121, 0.003961965333701273, -0.01135137087455493, -0.6850215009873762, -0.005413282049403616, -0.012148298923316394, 0.0044770528273252305, 0.012770292001043659, 0.028456174924119407, -0.0018352029810506495, 0.012977623026952746, 0.0017768911300137186, -0.013398763358423351, -0.008111824060386701, 0.027445436638473878, -0.005640050242576362, -0.004551562822214924, -0.006566560648192281, -0.012310276403723187, 0.009252144702886687, -0.012640709644189204, -0.0015873777014551818, -0.005251304568996822, -0.005471594016855865, 0.02162721135371455, -0.008455215722802672, -0.013722718319236939, 0.0026612872463688763, 0.007463914604420801, 0.0011484191905574324, -0.030062989443592293, -0.000715534823533406, 0.0008900653677506037, -0.014422460066018836, 0.0246723846326011, 0.027082608274455522, 0.038200731279201455, 0.04996676234292946, -0.003974923289989954, -0.02700485774275579, 0.017610173192387245, 0.011591097024016356, 0.021860459223523553, -0.006566560648192281, -0.010846000800409615, 0.02824884389821032, -0.017687923724086976, 0.011798428049925445, 0.017428759010378065, 0.01946319400361908, 0.020720138581023565, 0.010347110868561828, -0.00527074173626048, 0.00020652108088147145, 0.004801007788138818, -0.012297317981773232, -0.009394684550368548, 0.0055623011078604545, 0.0021024655443250945, 0.025605374249191994, -0.016353230477627857, 0.004289159434341075, 0.008468174144752628, -0.012828603968495908, 0.007535184993823006, -0.022741615152314626, 0.011902093562879988, -0.006679944511948017, 0.012757333579093703, -0.0042016914831627, -0.0027811505539302272, 0.015264742591605145, -0.031203310086092277, 0.023752353437960158, 0.017078889068309667, -0.0008179854262224825, -0.00333673265048652, -0.012167736556241327, -0.007612934128538914, 0.03918555272094707, -0.009925969605768673, 0.005426240005692296, 0.0016440697497483684, 0.015342491260659778, 0.018296958379864284, -0.0007118903255676404, -0.0006090347139849685, 0.01311368366345963, -0.009381726128418592, 0.014137380371055115, 0.005397084021966172, 0.005853860479460428, -0.015264742591605145, 0.014202171549482343, 0.01628843836787808, 0.008850441073018465, -0.019631651626323403, -0.0055396243351093066, -0.019527986113368857, -0.010178654177180056, 0.00519947181251955, 0.0029512268152251057, -0.044213327305274816, 0.014539084000923337, -0.023791228703810022, 0.022067790249432638, 0.005866818435749109, 0.009407642972318503, -0.00531285614193656, 0.003829143837020604, -0.004920870862869531, 0.031255143773892095, -0.02622736732691926, 0.02209370523068745, 0.007016857429050285, -0.012802687124595997, 0.0062328873365775014, 0.00042276080360243145, -0.015640530308896006, -0.01684564119850067, 0.008209010362366268, 0.0013751873837301789, -0.04118111244833822, 0.011228267728675452, 0.015329533770032372, 0.019631651626323403, 0.02599411945711026, 0.00802759618035709, 0.020033355256191623, -0.022249204431441818, 0.0006037704714831178, -0.015083327478273418, 0.012193652468818688, 0.006044993477932072, -0.019761232120532757, 0.04791936892773849, -0.03553134478628322, 0.03887455804472854, -0.014137380371055115, 0.04294342803121057, -0.004642269913219513, 0.02946691320976494, -0.020720138581023565, -0.025035214859264552, 0.022741615152314626, -0.0037999878532944792, -0.0004551562764007265, -0.027834181846392143, -0.015731237399900594, -0.014318794553064293, -0.002504169407023953, -0.010353590079536805, 0.01718255458126421, -0.020784928828128244, 0.01689747302365539, -0.030218488644346658, -0.0063916247458355325, -0.012161257345266348, -0.002544663544295014, 0.005601175442387771, -0.017856379484146197, -0.008960584865625438, -0.019165155886705403, -0.005941327964977528, 0.02599411945711026, -0.015355449682609733, 0.01623660654272336, 0.01899670012664618, 0.003168276424766023, -0.0076453292520912534, 0.02383010210701479, -0.010463734803466327, -0.015264742591605145, 0.002771431970298398, -0.03029623731340129, -0.027937847359346686, 0.011241226150625408, -0.014046673280050527, 0.007515747360898073, 0.011461514667161901, 0.007444477437157143, -0.007159397276532147, -0.0049565060575706334, -0.008714379505189032, -0.004269722267077417, -0.007068690185527558, -0.015329533770032372, 0.014875996452364329, -0.013100725241509674, 0.003544063676395608, 0.004315075812579711, -0.011947447108382284, 0.029855658417683204, 0.016819724354600756, 0.025177753775423865, 0.019826024230282534, -0.0033885654069637917, -0.002739036381084784, 0.023933767619969334, 0.01652168623768708, 0.00359589643287288, 0.007800827521523069, 0.01964460818562826, -0.011390245209082247, -0.006443457502312804, 0.023622771081105703, -0.01981306580833258, 0.0088115658071686, -0.01267958397871652, -0.002815165713056948, -0.03257687673575616, 0.015212909835127873, -0.0053776468547025134, -0.0011038754300116914, -0.012381545861802843, -0.007068690185527558, -0.012634230433214226, 0.010133300631677762, 0.01440950257539143, 0.004256763845127461, 0.007975763423879819, 0.00800167933645718, -0.01256296097513457, 0.015601655043046139, -0.00319095319751717, 0.011772511206025535, -0.0060320355216433915, 0.002745515592059762, 0.00014719688223352982, 0.012167736556241327, 0.004635790702244535, 0.0307886480342741, -0.05237698412213879, -0.007930409878377525, -0.0028993940587478334, -0.0067771308139275835, 0.03560909531798295, -0.0031083446545700287, -0.010645148985475505, 0.032680544111355805, -0.034676103838746954, 0.03449468965673778, -0.00035635008436592664, -0.008008158547432158, 0.0175065076794327, 0.026616112534837526, -0.003273561507633674, 0.011558700969141468, -0.0206812633151737, 0.02491859092436005, 0.010062031173598105, -0.025449876911082726, 0.012329713105325572, -0.015174035500600556, -0.005491031184119524, 0.00808590814780934, -0.005290179369185413, 0.010126822352025333, -0.0020943667634370096, 0.0033172954832228615, -0.009077208800529937, 0.035427677410683575, 0.01847837256187346, 0.004826924166377453, 0.0170400138024598, -0.011396724420057224, -0.004635790702244535, -0.0072241884549593734, 0.016651268594541534, 0.00046042051890257717, -0.00835155020984813, -0.010360069290511783, -0.008863398563645871, -0.00025855629814979674, -0.002178594876297258, 0.013411721780373307, -0.015316575348082416, 0.004554801962041138, -0.002641850079105218, -0.014111463527155204, -0.019890814477387213, 0.018828242503941862, -0.0009289399351085577, 0.0015995259892026274, -0.052765729330057055, 0.023713480034755388, 0.03436510916252842, -0.017973003419050698, -0.011915051053507396, -0.031125561417037644, 0.001784990027317122, -0.017571299789182475, -0.00011044828414886809, 0.005918651192226381, 0.01288043672497318, 0.011493910722036791, -0.015679403712100772, 0.005529905518646841, -0.007774911143284434, 0.03962613161666516, -0.028922670663737406, 0.016625351750641625, 0.0010034495225446363, -0.01499262038726883, -0.009252144702886687, -0.002926930239730214, -0.0024312794477086407, 0.029415081384610214, 0.006744735690375245, -0.023519107430796257, -0.0030986260709381995, 0.018789369100737096, -0.0005900023809919276, -0.018737535412937274, -0.005837662452022984, -0.00020419265809308335, 0.005215669839956994, 0.016534644659637034, -0.00265642807096828, -0.0013460315164193727, 0.019735317139277946, 0.016275479945928126, -0.01565348873084596, -0.011837302384452762, -0.014461335331868703, -0.025579457405292085, 0.015692362134050727, 0.12543522969680618, -0.0003482512452701825, -0.006913191916095742, 0.008947627374998032, 0.009556662030775341, -0.015057411565696057, -0.02752318530752851, -0.004234087072376314, 0.004661707080483171, -0.0022790207837643135, 0.021990039717732907, -0.02064238991196893, 0.006660507344684359, -0.002651568662737047, 0.001995560658713699, -0.022884155931119036, -0.010554441894470915, -0.01302945578343002, -0.002999819966214889, 0.00023102014627124595, -0.019489110847518993, 0.019631651626323403, 0.023376566651991847, 0.012005759075834533, -0.020603514646119068, -0.020059270237446435, -0.0030791889036745415, 0.02049984913316452, -0.025825663697051037, -0.0051314414942661086, -0.008312675875320813, -0.001700761798041555, 0.010560921105445894, 0.007956325790954885, 0.011500389933011768, 0.027575018995328333, -0.021031135119887197, 0.01999447999034176, 0.018089627353955195, -0.013003538939530108, 0.019735317139277946, 0.004302117390629755, 0.011617012936593719, -0.026667946222637347, 0.0175065076794327, -0.017286220094218756, -0.00639810395681051, 0.02874125461908313, 0.004626072351443343, -0.022741615152314626, 0.04263242962970184, 0.013333973111318674, 0.005338772520175197, -0.010178654177180056, 0.0011751454701679407, -0.0026499488599933028, -2.077865190332134e-05, -0.006336552849532046, -0.00947243321942318, 0.01542024086103696, -0.0070233366400252635, -0.018465414139923506, -0.010651628196450482, -0.0055623011078604545, -0.002233667238262019, -0.023091486957028125, 0.006349510805820727, 0.011124602215720909, -0.021912291048678274, -0.007904493034477614, -0.0008050272953108238, 0.013398763358423351, -0.02316923562608276, -0.007794348310548091, 0.01720846956251902, 0.009576098732377724, 0.022262162853391772, -0.03312112300707389, -0.017998920262950607, 0.02065534833391889, 0.005367928503901321, -0.015225868257077828, 0.0026450896845927065, -0.013502428871377896, 0.008636630836134399, 0.03669758041003802, 0.03001115761843757, 7.739478831379914e-05, 0.004136900770396748, 0.012109424588789077, 0.0274972703262737, 0.010049072751648151, 6.1045202683383e-05, -0.023817145547709934, -0.019864897633487304, -0.004075349197457009, 0.022067790249432638, 0.0072241884549593734, -0.003919850928025193, 0.0011200731082031798, 0.008597755570284533, -0.030944147235028467, -0.015381366526509644, 6.555019902889058e-05, -0.0069391082943343774, -0.012258443647245916, 0.010560921105445894, 0.00978990896926179, -0.034131861292719425, -0.016962265133405166, 0.020525765977064434, -0.02053872439901439, 0.02016293575040098, 0.017169596159314255, 0.003608854621992198, 0.023052611691178258, 0.02105705196378711, 0.03457244018843751, -0.0010471833817185048, -0.024737176742350875, -0.0014553662225617037, -0.010126822352025333, 0.016443937568632445, 0.011169955761223203, -0.017001138536609936, 0.01947615242556904, -0.001908092823950643, -0.010826564098807232, -0.0045936767622297295, -0.004823684560889965, -0.03231771574733745, 0.009109603924082277, -0.020888594341082787, -0.01313959957603699, -0.027989681047146508, -0.01834879020501901, 0.014046673280050527, -0.014020756436150616, -0.015601655043046139, -0.01267958397871652, -0.01972235871732799, -0.0035505428873705857, -0.004311836207092222, -0.019022616970546094, -0.009543703608825385, -0.024633511229396332, 0.00557201992432292, -0.0017380165626557646, 0.00737968672439119, 0.033172952969583516, -0.009485391641373136, 0.007334332713227621, -0.018633869899982728, 0.023557980834001024, -0.006537404664466157, -0.02293598775627376, 0.00909664643345487, -0.014577958335450654, 0.01348947138075049, 0.00861071399223449, 0.04330625639522893, -0.022197370743641996, 0.013904132501246117, -0.018426538874073643, -0.016819724354600756, 0.005682164182591168, 0.005704840955342315, -0.0007394264483423615, -0.02801559602840132, -0.008688463592611672, 0.02848209176801932, 0.025786788431201173, 0.012867478303023224, -0.015497989530091594, 0.009783429758286813, 0.03052948518321029, 0.011791948838950466, -0.00114436980011339, 0.0014675145103091494, -0.025294377710328362, -0.008448736511827695, -0.02261203279546017, 0.0036023756438478575, -0.0007641279745231892, 0.015303616926132461, -0.00877917068361626, 0.009485391641373136, 0.0020117582204898683, -0.0009508068646954921, 0.000644264783377157, 0.01140968191068463, -0.017662006880187063, 0.029363247696810393, 0.00466494668597066, 0.0052091906289820165, -0.0008232497269319924, -0.010094426297150445, -0.008921710531098121, 0.02016293575040098, -0.0045936767622297295, 0.022845280665269172, -0.008850441073018465, -0.016625351750641625, -0.00712052294200483, 0.0020506327878478227, 0.012550002553184616, -0.005238346612708141, -0.013359889023896034, -0.007366728302441235, -0.01941136217846436, -0.011856740017377694, 0.0017056212062727882, -0.005040733937600245, -0.012543523342209636, -0.00712052294200483, -0.030633150696164832, -0.008675505170661716, 0.01166884569307099, -0.024283639424682833, -0.022106663652637408, -0.026538363865782892, -0.005192992601544572, 0.021938207892578183, -0.014318794553064293, 0.020253644704050666, 0.012951706183052835, -0.015031494721796147, -0.02345431532104648, 0.03366536555310142, 0.0084033829663254, -0.0009070730055216234, 0.01793412815320083, -0.010580358738370826, -0.002487971612417146, 0.006074149461658197, 0.004561281173016116, -0.0031585576083035566, -0.007697162008568525, -0.0399630431367836, -0.017338051919373477, 0.02333769138614198, -0.0016384005565605814, -0.018413582314768785, -0.011370807576157313, -0.012711980033591409, 0.015122202744123283, -0.011617012936593719, -0.020227727860150757, -0.014694582270355153, -0.007425040269893484, -0.0025802987389961164, -0.019333613509409726, -0.014565000844823248, 0.0034436377689285526, 0.0011289819068784554, 0.0008187953275943546, -0.0027050212219580636, -0.025035214859264552, -0.017130720893464388, -0.0076842040522798446, 0.014668665426455242, 0.018011876822255465, -0.004894954484630895, -0.005772871739257031, -0.0041239423484467925, 0.01412442194910516, -0.007567580117375345, 0.005354970081951366, 0.008442258232175266, 0.019877856055437258, 0.004376626919858175, 0.008584798079657128, 0.002491211217904635, 0.02521662904127373, -0.0057858296955457114, 0.007366728302441235, 0.008150698394914018, -0.021303256392900965, -0.029104084845746583, 0.001700761798041555, 0.023013736425328394, 0.013593136893705034, -0.0016027655946901163, 0.004836642517178646, -0.02721218876866488, -0.03208446787752845, -0.023791228703810022, -0.010204571021079967, -0.011856740017377694, -0.038615393331019626, -0.015368408104559689, -0.023959684463869244, 0.012660147277114137, -0.0001650143922725921, -0.009407642972318503, 0.0003097816285981646, 0.0033820864288194516, 0.027834181846392143, -0.03104781274798301, 0.010962624735314114, -0.007088127352791216, -0.0024733936205540838, -0.01814145917910992, 0.002556002163501225, 0.015562780708518822, -0.006738256479400267, 0.02176975213251896, -0.008960584865625438, -0.01900965854859614, -0.007418561058918507, -0.0019194312103262166, 0.0009200311364332821, 0.0013355030314156713, -0.014396544153441476, -0.008571839657707173, 0.0019437277858211084, 0.012213090101743622, -0.02228807969729168, -0.029389164540710305, 0.0041401403758842365, -0.004752414637149035, -0.019100365639600728, 0.01978714896443267, -0.015199951413177917, 0.029674244235674028, 0.015899693159959816, 0.012848040670098293, 0.021199590879946422, -0.027082608274455522, -0.006634590966445723, 5.8868632764242234e-05, 0.023661646346955566, -0.01204463341036185, -0.009550182819800364, -0.01135137087455493, -0.019216989574505225, -0.01605519236071418, -0.006757693646663925, 0.008364508631798084, -0.014318794553064293, -0.009148479189932142, 0.013463554536850579, 0.007794348310548091, 0.0009499969633236198, 0.01611998260781886, 0.01718255458126421, -0.006848401203329788, -0.012226047592371028, -0.034391022281138134, -0.021679045041514373, 0.0014343091361389822, 0.025579457405292085, 0.007204751287695715, -0.016729017263596168, -0.034157778136619334, 0.021044093541837155, -0.02605891156686004, -0.00353110548727629, -0.006219928914627547, 0.018633869899982728, 0.015446156773614323, 0.011675324904045967, 0.0012804306694509104, -0.010709940163902733, -0.007658287674041208, 0.020292518107255433, 0.0035149076926694832, -0.016340272055677903, -0.007010378218075308, 0.01450020966639602, 0.01308776681955972, 0.01584786133480509, -0.0011581377741892616, -0.0019518266831245116, -0.006595716166257132, 0.015990400250964404, 0.00990653290416629, -0.0036930827348524466, -0.02556649898334213, -0.007748994765045797, -0.01926882139965995, 0.012660147277114137, 0.003968444079014976, -0.010664586618400437, -0.02495746432756482, -0.0030451735117171834, -0.0031002458736819442, -0.00927158140448907, -0.01548503110814164, -0.0014926209871759131, 0.004833403377352431, 0.0066540281337093814, 0.0023762073185745174, 0.008507048479279945, 0.005105525116027472, 0.01551094795204155, -0.0006349510922236045, -0.030244405488246567, 0.030555402027110202, -0.03700857881154675, 0.0015598415204728013, -0.0015161076612989325, -0.009465954008448203, -0.00580526686280937, -0.0013719478946580088, -0.002034434993241016, -0.02881900515078286, -0.006278240882079796, -0.02204187340553273, -0.011694762536970901, 0.01819329286690974, -0.012873957513998202, 0.0034857519417739956, -0.019126282483500637, 0.0033237744613672016, -0.0003223348670315465, -0.009135520767982188, -0.01830991680181424, 0.05204007260202034, -0.006589237420943428, -0.017001138536609936, -0.012031674988411895, 0.00947243321942318, 0.0009362288728324296, -0.014215129040109749, -0.02570903976214654, 0.0008657687340480528, -0.006553602226242326, -0.009621452277880018, 0.002483112204185913, -0.003297858083128566, -0.009893574482216335, -0.01597744182901445, -0.0032136299702683175, -0.019022616970546094, -0.0010099286171042954, 0.25232177284968577, -0.01744171743232802, 0.006848401203329788, 0.010826564098807232, -0.011908572773854967, 0.019761232120532757, 0.011778990417000512, -0.007353770346152554, -0.0072371464112480546, 0.016366188899577812, -0.012686063189691498, -0.007340811924202598, -0.0011889135606591309, 0.00699094105081165, -0.0019550662886120007, -0.019229947996455183, -0.021277339549001052, 0.0066086745882070865, -0.012783249491671065, -0.043073008525419926, 0.0005491031184119523, -0.011824343962502806, -0.01810258577590515, -0.0340800276049196, 0.02556649898334213, 0.013308056267418763, -0.013554261627855167, -0.002185074087272236, 0.011007978280816408, 0.029855658417683204, 0.008947627374998032, 0.0024167016886762157, -0.007910972245452591, -0.003576459265609222, -0.017584258211132433, -0.00340152359608311, 0.02879308830688295, -0.005040733937600245, 0.009265102193514093, 0.02500929801536464, 0.01862091334067787, -0.02617553363911944, -0.014435418487968792, -0.0062004917473638885, -0.01783046264024629, 0.013554261627855167, -0.00272121901656487, -0.012951706183052835, -0.02169200160081923, 0.018672745165832595, -0.019592776360473536, -0.01900965854859614, 0.002820025121288181, 0.02519071219737382, 0.0024377586586836184, 0.00387125777703541, 0.010010198417120834, 0.010217529443029923, 0.01689747302365539, -0.014254004305959614, 0.003121302843689347, 0.01830991680181424, -0.016884516464350532, 0.0034760331253115293, -0.017117762471514433, 0.033769032928701065, -0.01670310041969626, 0.01617181629561868, 0.0046714258969456374, -0.019385445334564447, -0.0004434129102353871, 0.0038777369880103876, -0.0013346931300437992, 0.022456535457350903, -0.019851939211537346, -0.026927109073701157, 0.05258431514804787, 0.015459115195564277, 0.0023664885021120506, 0.008591277290632105, -0.009802867391211745, 0.009394684550368548, -0.00037437006974795693, 0.009556662030775341, -0.035946006838101396, -0.03433919231862851, 0.006550362620754837, -0.01288043672497318, -0.017947086575150786, -0.011778990417000512, 0.01311368366345963, -0.031125561417037644, -3.497697521347836e-05, 0.003945767306263829, 0.02617553363911944, 0.008941148164023053, 0.02310444537897808, 0.028378426255064773, -0.015044453143746101, -0.008902273829495738, -0.019100365639600728, -0.04711596166800205, 0.016340272055677903, 0.030477651495410468, -0.02399855972971911, 0.01626252338662327, 0.009511308485273047, 0.018504289405773373, 0.00016136990885874132, -0.020810845672028153, 0.015549822286568867, -0.035997840525901215, 0.0138652581667188, -0.008824524229118554, 0.013249744299966512, 0.003670405962101299, -0.016936348289505257, -0.0009929209211256163, 0.012329713105325572, 0.004729737864397887, 0.009401163761343525, 0.0032994778858723103, 0.018296958379864284, -0.000992111019753744, 0.011156997339273247, -0.011649408991468607, -0.006430499546024124, -0.009712160300207157, 0.006148658990886616, -0.03931513321515643, -0.0038226646260456267, -0.018776410678787138, -0.007457435859107098, 0.000985631925194085, -0.006401343562297998, -0.004321555023554689, 0.0002911542171872301, -0.019022616970546094, -0.01611998260781886, -0.0019890814477387213, 0.021536504262709963, -0.005513707956870671, 0.012783249491671065, -0.017895254749996065, -0.0031747554029103635, -0.03369128239700134, 0.010379506923436716, 0.017739755549241697, -0.001752594554518827, -0.015446156773614323, -0.039755712110874517, -0.005698362210028612, -0.011617012936593719, 0.010956145524339137, 0.018387665470868873, -0.006556841831729815, -0.031747552632119806, -0.00473621660971159, -0.003501949503550165, 0.01720846956251902, -0.03312112300707389, 0.0056076546533627486, 0.012452816251205048, -0.016612393328691667, -0.013839342254141438, 0.026823443560746615, -0.1669014348786238, 0.0024280400750517892, 0.022974863022123624, -0.023635729503055657, 0.024555760697696598, -0.010677545040350393, 0.018089627353955195, -0.0024733936205540838, -0.013955965257723389, 0.027108523255710334, 0.00909664643345487, -0.005698362210028612, -0.014085547614577844, -0.022365828366346315, -0.0014586057116338738, 0.010820084887832255, -0.013068330117957334, 0.01999447999034176, 0.015148118656700646, 0.0027179794110773815, 0.03200671734582872, 0.00038186151191862657, 0.016081107341968992, 0.006547123015267348, 0.02495746432756482, 0.012459295462180026, 0.016871558042400578, -0.012634230433214226, 0.003424200601664894, -0.025087046684419273, 0.0004859319464552771, -0.016754934107496077, -0.008332113508245744, -0.0173898856071733, 0.013839342254141438, -0.007016857429050285, -0.009265102193514093, -0.01565348873084596, -0.00332053508871035, 0.02423180759952811, 0.03636066888991957, 0.020888594341082787, 0.016042233938764226, 0.010606274650948188, 0.007554622161086664, 0.030814564878174012, 0.007548142950111686, -0.016936348289505257, 0.00162787207155688, 0.005102285510539983, 0.006556841831729815, -0.01542024086103696, -0.007800827521523069, 0.003806467064269457, 0.014837122117837014, 0.012213090101743622, -0.004347471401793325, 0.01094318803371173, -0.0027098806301892966, -0.008267322329818517, 0.004645509518707002, -0.0033691282397001333, 0.010936708822736754, -0.013968923679673343, 0.007042773807288922, 0.014863038961736923, 0.013657927140809711, 0.015083327478273418, -0.01906149037375086, -0.01172715766052324, -0.012122382079416483, -0.013308056267418763, 0.021730876866669097, -0.019657566607578215, 0.006372187578571874, -0.011740116082473195, -0.007787869565234388, 0.011422640332634586, 0.014474292822496109, 0.0015873777014551818, -0.01643097914668249, 0.042269601265683486, -0.017428759010378065, 0.013035934063082446, -0.013917090923196072, 0.018737535412937274, 0.01117643497219818, 0.0009329893255526001, -0.0016910432144097258, -0.022663866483259992, 0.04221776757788366, -0.023674604768905524, -0.006210210563826354, -0.006679944511948017, 0.002505789209767697, 0.029155916670901307, 0.0016513587456798995, 0.0028686182722779644, 0.027367687969419244, -0.0008973543636821349, 0.008500569268304968, -0.012148298923316394, -0.005361449292926344, -0.009427079673920886, 0.0025883975198842013, 0.00903833446600262, -0.010262882988532217, 0.011500389933011768, 0.033483951371092245, -0.016560561503536946, 0.0015088186653674015, 0.023622771081105703, 0.0033496908396058378, -0.008688463592611672, -0.008889315407545782, 0.006424020335049146, -0.0075805385393253, -0.03353578505889207, 0.02437434651568742, -0.01649576939378717, 0.03799340025329236, 0.013476512958800533, -0.0084033829663254, 0.0132821403548414, -0.007748994765045797, 0.0074768730263707565, -0.08858215567394909, 0.006109784190698025, 0.01779158923704152, -0.007664766885016186, -0.01192800947545735, 0.006738256479400267, -0.013424680202323262, -0.014552042422873291, -0.0018190053028591614, 0.021160717476741652, -0.007282500422411624, -0.003939288560950126, -0.014798247783309697, -0.007483352237345734, 0.018633869899982728, -0.008759733050691327, 0.02486675723656023, -0.015031494721796147, -0.019372486912614492, 0.020746055424923478, -0.0069326290833594, 0.005150878661529767, 0.010496129927018667, -0.015459115195564277, -0.025838622119000995, -0.012886915004625608, -0.009751034634734474, 0.01236210916020046, 0.01360609438433244, 0.00958905715432768, 0.006517967031541223, -0.01062571228387312, -0.003592656827385391, -0.01718255458126421, 0.012394504283752798, 0.0017817505382449518, -0.03947063427855589, 0.022365828366346315, 0.012575919397084525, -0.01828399995791433, 0.004606634718518411, -0.006965024672573013, 0.008798608316541194, -0.03255095989185625, -0.005727517728093462, 0.007800827521523069, -0.010094426297150445, 0.03166980582571027, 0.030710899365219466, -0.01906149037375086, 0.00719179286574576, -0.005021296770336587, -0.03356170190279198, -0.011221788517700474, 0.016923389867555302, 0.010146259053627716, 0.026616112534837526, 0.020525765977064434, -0.0056076546533627486, 0.0030808084735876482, 0.011014457491791387, -0.007055731763577602, -0.006563321042704792, -0.007068690185527558, -0.0024118422804449823, 0.005698362210028612, -0.022780490418164493, 0.011772511206025535, 0.02322106745123748, -0.02669386120389216, -0.021355090080700787, 0.010593316228998232, -0.01334693060194608, 0.010262882988532217, -0.011247705361600385, -0.003424200601664894, -0.006790089235877539, -0.01628843836787808, 0.005186513856230869, -0.02491859092436005, -0.004295638645316052, -0.01718255458126421, 0.006566560648192281, -0.011785469627975489, -0.0014108224620159628, 0.011331933241629996, 0.007898013823502636, 0.004732977004224101, -0.008377467053748039, -0.006333313244044557, 0.0015525526409565886, 0.01565348873084596, 0.018374707048918918, -0.001412442264759707, -0.01111812300474593, 0.006790089235877539, -0.00392956974448766, 0.002259583616500655, 0.011675324904045967, 0.02197708315842805, 0.0009661946997227673, -0.01473345660488247, -0.058311833341802614, 0.024503928872541877, -0.009219748648011799, -0.01426696179658702, 0.009465954008448203, -0.00457747920045356, 0.016210689698823447, -0.022650908061310038, -0.02754910215142842, -0.00228873960022678, -0.017985961841000653, 0.029907492105483026, 7.952073575921919e-05, 0.002410222477701238, -0.0206812633151737, -0.01048317243639126, 0.004085068013919476, -0.004687623458721807, 0.005973723554191142, 0.005406802838428638, 0.019048531951800906, 0.003479272730799018, 0.002682344449206916, 0.023661646346955566, -0.01377455107571421, 0.001121692910946924, -0.01862091334067787, 0.02197708315842805, 0.0029722837852325084, -0.003414481785202428, 0.009880616060266379, -0.027678684508282876, -0.006592477026430918, -0.0023340931457290744, 0.006757693646663925, -0.017169596159314255, 0.018867117769791726, 0.005876537252211576, -0.007068690185527558, 0.03576459265609221, -0.021549462684659917, -0.0036574477729819812, 0.030607233852264923, -0.005196232207032061, 0.005238346612708141, 0.001456986025305448, 0.003631531394743345, 0.004376626919858175, 0.037682401851783634, 0.0038129460424137975, 0.018569079652878052, 0.02013702076914617, -0.01115051812829827, -0.01946319400361908, -0.007619412873852617, 0.007198272076720738, 0.029907492105483026, 0.0085200069012299, 0.001569560220519949, -0.02868942279392841, 0.0033885654069637917, -0.01862091334067787, 0.0003672835782632235, 0.004363668963569494, 0.013502428871377896, -0.011202350884775543, 0.0034987101308933135, 0.027911930515446777, 0.01452612557897338, -0.030555402027110202, -0.0019064730212068988, -0.011960405530332239, 0.00828675996274345, 0.03029623731340129, 0.012381545861802843, 0.022573159392255404, 0.022365828366346315, -0.011040374335691298, -0.035686842124392486, 0.027834181846392143, 0.009381726128418592, -0.005989921115967311, -0.008157177605888995, -0.0019340092021892792, 0.0317216395135101, 0.006096826234409344, -0.019657566607578215, 0.02096634487278252, 0.007781390354259411, 0.016793807510700847, 0.01302945578343002, 0.004256763845127461, -0.016068150782664135, -0.012452816251205048, -0.00802759618035709, 0.01783046264024629, -0.011299538118077657, 0.010321194955984466, 0.017752713971191655, -0.0005357399786066983, 0.0038582995879160916, -0.019489110847518993, -0.001635970852444965, -0.015938568425809683, -0.006443457502312804, 0.026395823086978482, -0.010962624735314114, -0.010172175897527627, -0.009122562346032231, 0.011027415913741342, 0.020383225198260024, -0.0057469553610183955, 0.015044453143746101, 0.03052948518321029, -0.012640709644189204, 0.025462833470387584, 0.0053096165364490714, 0.0005001049585285737, -0.0272640224564647, 0.02296190460017367, -0.009057771167605004, -0.018582038074828007, -0.0015679404177762046, -0.013800467919614121, 0.005351730476463877, 0.01323030759836413, -0.007301937589675281, 0.0063138756111196246, 0.004230847466888826, -0.02230103625659654, -0.011876176718980079, -0.016469854412532358, -0.017195511140569067, -0.009569619521402747, 0.01548503110814164, 0.0013970543715247725, 0.003615333832967176, 0.012323233894350593, -0.04068870359011051, 0.043461753733338195, 0.003838862420652433, -0.03965204846056507, 0.016392103880832624, -0.0007503599422396583, 0.019955604724491892, -0.009278060615464047, -0.006647548922734403, -0.04144027716204713, -0.0017817505382449518, -0.008299717453370856, -0.01689747302365539, 0.017584258211132433, -0.028041512872301232, -0.007541663739136709, 0.0031115842600575178, -0.015938568425809683, 0.006184294185587719, -0.016275479945928126, 0.0037384365131853782, 0.025035214859264552, 0.009666806754704863, 0.03698266196764684, 0.012906352637550541, -0.01600335867291436, 0.00040737293947132645, -0.0038032274587819683, 0.014875996452364329, -0.020422100464109888, -0.02084972093787802, 0.007567580117375345, 0.0063235944275820905, -0.03936696690295625, -0.01605519236071418, 0.012971143815977769, 0.0012107804320384058, -0.015277701013555101, -0.010988541579214025, 0.032369545709847077, 0.01981306580833258, -0.024685343054551053, 0.01617181629561868, -0.015821944490905182, 0.0023259943648409895, 0.0068613591596184695, 0.01577011080310536, -0.0061227426126479806, 0.00869494280358665, -0.016301396789828036]\n"
     ]
    }
   ],
   "source": [
    "# Import and instantiate OpenAI embeddings\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "#instead of using 'ada' model, use default one as per this tutorial: https://blog.bytebytego.com/p/how-to-build-a-smart-chatbot-in-10\n",
    "embeddings = OpenAIEmbeddings(openai_api_key = OPEN_AI_KEY)\n",
    "     \n",
    "\n",
    "# Turn the first text chunk into a vector with the embedding\n",
    "\n",
    "query_result = embeddings.embed_query(texts[0].page_content)\n",
    "print(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='before them. Allister was in his element, leaving everything on the court as he chased his dreams.', metadata={}), Document(page_content=\"townspeople's support and admiration boosted Allister's confidence, and he continued to train\", metadata={}), Document(page_content='The tournament day arrived, and Allister stood proudly on the rectangular court, with his teammates', metadata={}), Document(page_content=\"victory. Allister's face beamed with pride as he hugged his teammates, celebrating a job well done.\", metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# Import and initialize Pinecone client\n",
    "\n",
    "import os\n",
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_KEY,  \n",
    "    environment=PINECONE_ENV \n",
    ")\n",
    "     \n",
    "\n",
    "# Upload vectors to Pinecone\n",
    "\n",
    "index_name = \"langchain-quickstart\"\n",
    "search = Pinecone.from_documents(texts, embeddings, index_name=index_name)\n",
    "     \n",
    "\n",
    "# Do a simple vector similarity search\n",
    "\n",
    "query = \"What sport did Allister renowned for?\"\n",
    "result = search.similarity_search(query)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to solve a quadratic equation\n",
      "Action: Python REPL\n",
      "Action Input: import numpy as np\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I can use the numpy function to solve the equation\n",
      "Action: Python REPL\n",
      "Action Input: np.roots([3,2,-1])\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: (-1.0, 0.3333333333333333)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'(-1.0, 0.3333333333333333)'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Python REPL tool and instantiate Python agent\n",
    "\n",
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.python import PythonREPL\n",
    "from langchain.llms.openai import OpenAI\n",
    "\n",
    "agent_executor = create_python_agent(\n",
    "    llm=OpenAI(temperature=0, max_tokens=1000, openai_api_key = OPEN_AI_KEY),\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")\n",
    "     \n",
    "\n",
    "# Execute the Python agent\n",
    "\n",
    "agent_executor.run(\"Find the roots (zeros) if the quadratic function 3 * x**2 + 2*x -1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
